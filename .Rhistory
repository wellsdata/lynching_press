pct_ind = round(oth_received / oth_sent * 100, 1)
)
View(voters_by_county)
# Top 5 counties by each category
top_voters_by_category <- list(
pct_received = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_received)) |>
slice_head(n = 5),
pct_dem = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_dem)) |>
slice_head(n = 5),
pct_gop = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_gop)) |>
slice_head(n = 5),
pct_ind = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_ind)) |>
slice_head(n = 5)
)
top_voters_by_category
View(top_voters_by_category)
top_voters_by_category |>
unlist() |>
as.data.frame()
# Top 5 counties by each category
pct_received = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_received)) |>
slice_head(n = 5)
pct_dem = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_dem)) |>
slice_head(n = 5)
pct_gop = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_gop)) |>
slice_head(n = 5)
pct_ind = voters_by_county |>
select(county_name, pct_received, pct_dem, pct_gop, pct_ind) |>
arrange(desc(pct_ind)) |>
slice_head(n = 5)
View(pct_dem)
View(pct_gop)
View(pct_ind)
View(pct_received)
View(pct_ind)
View(pct_gop)
View(pct_dem)
lender_types <- read_csv("images/tabula-PPP_Report_Public_210531-508.csv") |>
clean_names()
lender_types
lender_types <- read_csv("images/tabula-PPP_Report_Public_210531-508.csv", skip=1, col_names=c("type", "count", "approved", "net_dollars"))
lender_types <- lender_types  |>  mutate(net_dollars=as.numeric(parse_number(net_dollars)))
lender_types
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("tigris")
#install.packages("zoo")
library(tigris)
library(stringr)
library(janitor)
library(zoo)
library(lubridate)
library(readtext)
#metadata for 11,396 articles observed by coding team. 19% of all 60,042 entries in search
master_article_index_june_26_2024 <- read_csv("https://osf.io/download/fuh3m/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
#Index of 11,223 articles of text extracted from 60,000 lynching articles: 18.7% of all 60,042 search captured
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/hzyw6/?view_only=6c106acd6cb54f6f849e8c6f9098809f") %>%
as.data.frame()
main_index <- read_csv("https://osf.io/download/hda4v/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
getwd()
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("tigris")
#install.packages("zoo")
library(tigris)
library(stringr)
library(janitor)
library(zoo)
library(lubridate)
library(readtext)
master_article_index_june_26_2024 <- read_csv("https://osf.io/download/fuh3m/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/p32he/") %>%
as.data.frame()
View(extracted_articles_index_june_22_2024)
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/7kpr4/files/osfstorage/667750b76ef99d02d22d7605") %>%
as.data.frame()
download.file("https://osf.io/download/p32he/", destfile = "extracted_articles_index_june_22_2024.csv", mode = "wb")
library(httr)
url <- "https://osf.io/download/p32he/"
response <- GET(url)
# Check if the file is what we expect
if (http_type(response) == "application/octet-stream") {
# Write the content to a file
writeBin(content(response, "raw"), "extracted_articles_index_june_22_2024.csv")
}
# Now read the file into R
extracted_articles_index_june_22_2024 <- read_csv("extracted_articles_index_june_22_2024.csv") %>%
as.data.frame()
main_index <- read_csv("https://osf.io/download/hda4v/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
extracted_articles_index_june_22_2024 <- read_csv("extracted_articles_index_june_22_2024.csv") %>%
as.data.frame()
master_article_index_june_26_2024 <- read_csv("https://osf.io/download/fuh3m/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
main_index <- read_csv("https://osf.io/download/hda4v/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/z39ku/") %>%
as.data.frame()
extracted_articles_index_june_22_2024 <- read_csv("https://mfr.osf.io/render?url=https%3A%2F%2Fosf.io%2Fdownload%2Fz39ku%2F%3Fdirect%26mode%3Drender") %>%
as.data.frame()
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/7kpr4/files/osfstorage/67098ad3f47339a9fe015050") %>%
as.data.frame()
View(extracted_articles_index_june_22_2024)
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/7kpr4/?view_only=67098ad3f47339a9fe015050") %>%
as.data.frame()
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/7kpr4/?view_only=6c106acd6cb54f6f849e8c6f9098809f") %>%
as.data.frame()
extracted_articles_index_june_22_2024 <- read_csv("https://osf.io/download/z39ku/?view_only=6c106acd6cb54f6f849e8c6f9098809f") %>%
as.data.frame()
#303184 rows, articles span multiple rows for tokenization
extracted_text_june_22_2024 <- read_csv("https://osf.io/download/p32he/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
#subset 9589 mainstream white owned paper articles to eliminate Black newspapers
lynch1 <- lynch %>%
filter(black_press != "Y" | is.na(black_press))
View(extracted_text_june_22_2024)
lynch1 <- extracted_text_june_22_2024 %>%
filter(black_press != "Y" | is.na(black_press))
lynch1 <- extracted_articles_index_june_22_2024 %>%
filter(black_press != "Y" | is.na(black_press))
View(lynch1)
lynch1a <- extracted_text_june_22_2024 %>%
filter(black_press != "Y" | is.na(black_press))
# 1650 from the black press
# from master_article_index_6_17 has 11,396 articles
# June 22 data cleaning and compiling
black_press_master_june_26_2024 <- master_article_index_june_26_2024 %>%
filter(black_press =="Y")
# black_press_master_june_26_2024 <- read_csv("#https://osf.io/download/e84j3/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
black_press_extracted_text_june_22_2024 <- read_csv("https://osf.io/download/t75k2/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
#write.csv(black_press_master_june_26_2024, "../data/blackindex_master_june_26_2024.csv")
bp <- black_press_master_june_26_2024 %>%
count(newspaper_name) %>%
arrange(desc(n))
#write.csv(bp, "../output_images_tables/bp_newspapers.csv")
View(black_press_master_june_26_2024)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press1 = case_when(
black_press!="Y" ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ cleaned_company
))
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press1 = case_when(
black_press!="Y" ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press1
))
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press1 = case_when(
black_press!="Y" ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
View(lynch2)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press1 = case_when(
black_press== is.na(black_press) ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
View(lynch2)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
View(lynch2)
lynch2 |>
count(black_press1)
View(black_press_master_june_26_2024)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press1)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y " ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press1)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y  " ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press1)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press==" Y" ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press1)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press1 = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="  Y" ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press1)
lynch2 |>
count(black_press)
lynch2 <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
lynch2 |>
count(black_press)
lynch1 <- lynch %>%
filter(black_press == "N")
lynch <- extracted_articles_index_june_22_2024 |>
mutate(black_press = str_squish(black_press)) |>
mutate(black_press = case_when(
black_press != "Y" | is.na(black_press) ~ "N",
black_press=="Y" ~ "Y",
TRUE ~ black_press
))
lynch1 <- lynch %>%
filter(black_press == "N")
lynch |>
count(black_press)
black_press_master_june_26_2024 <- extracted_articles_index_june_22_2024 %>%
filter(black_press =="Y")
xblack_press_master_june_26_2024 <- read_csv("#https://osf.io/download/e84j3/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
xblack_press_master_june_26_2024 <- read_csv("https://osf.io/download/e84j3/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
write.csv(black_press_master_june_26_2024, "../data/blackindex_master_june_26_2024.csv")
blackindex_master <- read.csv("../data/extracted_articles_index_june_22_2024") %>%
filter(black_press =="Y")
blackindex_master <- read.csv("../data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
getwd()
setwd("~/Code/lynching_press")
blackindex_master <- read.csv("../data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
getwd()
blackindex_master <- read.csv("data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
blackindex_master <- read.csv("/data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
blackindex_master <- read_csv("/data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
blackindex_master <- read_csv("../data/extracted_articles_index_june_22_2024.csv") %>%
filter(black_press =="Y")
black_press_master_oct_11_2024 <- extracted_articles_index_june_22_2024 %>%
filter(black_press =="Y")
write.csv(black_press_master_oct_11_2024, "../data/blackindex_master_oct_11_2024.csv")
blackindex_master <- read_csv("https://osf.io/download/4m9zc/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
blackindex_master <- read_csv("https://osf.io/download/hzd5g/?view_only=6c106acd6cb54f6f849e8c6f9098809f")
View(blackindex_master)
bp <- black_press_master_oct_11_2024 %>%
count(newspaper_name) %>%
arrange(desc(n))
View(bp)
write.csv(bp, "../output_images_tables/bp_newspapers.csv")
years_10_11 <- extracted_articles_index_june_22_2024 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
View(years_10_11)
write.csv(years_10_11, "../output_images_tables/years_of_news_coverage_10_11_2024.csv")
old_master_article_index_10.19 <- read.csv("../data/old_article_indexes_lists/master_article_index_10.19.csv")
totals_10_11 <- extracted_articles_index_june_22_2024 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
View(totals_10_11)
year_compare %>%
filter(year < "1862") %>%
summarize(sum(count))
old_master_article_index_10.19 <- read.csv("/Users/robwells/Code/lynching_press/storage_old_article_indexes_lists/master_article_index_10.19.csv")
years_10_19 <- old_master_article_index_10.19 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
rename(pct_whole_old = pct_whole, count_old = count) %>%   mutate(rank_old = dense_rank(desc(pct_whole_old)))
year_compare <- years_10_19 %>%
inner_join(years_6_18, by="year") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
year_compare <- years_10_19 %>%
inner_join(years_10_11, by="year") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
year_compare %>%
filter(count_old > count)
compare <- totals_10_11 %>%
inner_join(totals_10_19, by="newspaper_state") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count_old = n) %>%
mutate(pct_whole = round(count_old/sum(count_old)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
compare <- totals_10_11 %>%
inner_join(totals_10_19, by="newspaper_state") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
year_compare %>%
filter(year < "1862") %>%
summarize(sum(count))
year_compare %>%
filter(year < "1862") %>%
summarize(sum(diff))
tolnay_beck <- read_csv("../data/Bailey_Beck_lynching_list_8_1_2022.csv") %>%
as.data.frame()
tolnay_beck <- janitor::clean_names(tolnay_beck)
View(tolnay_beck)
tolnay_beck |>
count(status)
names(tolnay_beck)
tolnay_beck |>
count(status_clean)
tolnay_beck <- tolnay_beck %>%
mutate(
status_clean = case_when(
status_clean == 'coincident death' ~ 'coincidental death',
status_clean == 'possiible lynching' ~ 'possible lynching',
TRUE ~ status_clean
))
tolnay_counts <- tolnay_beck %>%
count(status_clean) %>%
mutate(pct_total = round(n/5871, 3)) %>%
mutate(pct_total = formattable::percent(pct_total, 1)) |>
rename(Category = status_clean, Number = n, Pct_Total = pct_total)
nice_table(tolnay_counts, short = TRUE)
library(tidyverse)
#install.packages("sampler")
library(sampler)
#install.packages("rio")
library(rio)
#install.packages("kableExtra")
#install.packages("formattable")
library(formattable)
library(kableExtra)
library(knitr)
library(here)
tolnay_beck <- tolnay_beck %>%
mutate(
status_clean = case_when(
status_clean == 'coincident death' ~ 'coincidental death',
status_clean == 'possiible lynching' ~ 'possible lynching',
TRUE ~ status_clean
))
tolnay_counts <- tolnay_beck %>%
count(status_clean) %>%
mutate(pct_total = round(n/5871, 3)) %>%
mutate(pct_total = formattable::percent(pct_total, 1)) |>
rename(Category = status_clean, Number = n, Pct_Total = pct_total)
nice_table(tolnay_counts, short = TRUE)
nice_table::nice_table(tolnay_counts, short = TRUE)
library(kableExtra)
kbl(tolnay_counts) %>%
kable_paper(full_width = F) %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(2, width = "5em", background = "yellow")
tolnay_graphic <- tolnay_counts %>%
arrange(desc(n)) %>%
kbl(caption = "Lynching Totals, Tolnay & Beck, 2022", font_size = 30) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(2, width = "5em", background = "yellow")
library(rempsyc)
nice_table(tolnay_counts, short = TRUE)
library(kableExtra)
kbl(tolnay_counts) %>%
kable_paper(full_width = F) %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(2, width = "5em", background = "yellow")
tolnay_graphic <- tolnay_counts %>%
arrange(desc(n)) %>%
kbl(caption = "Lynching Totals, Tolnay & Beck, 2022", font_size = 30) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(2, width = "5em", background = "yellow")
tolnay_graphic <- tolnay_counts %>%
arrange(desc(Number)) %>%
kbl(caption = "Lynching Totals, Tolnay & Beck, 2022", font_size = 30) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(2, width = "5em", background = "yellow")
library(webshot)
# Save the kable table as an image
temp_html <- tempfile(fileext = ".html")
save_kable(tolnay_graphic, file = temp_html)
img_file <- tempfile(fileext = ".png")
webshot(temp_html, file = img_file, zoom = 2) # Adjust zoom to
library(webshot)
# Save the kable table as an image
temp_html <- tempfile(fileext = ".html")
save_kable(tolnay_graphic, file = temp_html)
img_file <- tempfile(fileext = ".png")
webshot(temp_html, file = img_file, zoom = 2) # Adjust zoom to
img <- grid::rasterGrob(png::readPNG(img_file), interpolate = TRUE)
ggsave("tolnay_graphic.png", plot = ggplot() + annotation_custom(img, xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf), dpi = 800, width = 10, height = 10)
tolnay_beck %>%
count(year) %>%
group_by(year)
tolnay_beck %>%
count(year)
tolnay_beck %>%
count(year) %>%
sum(n)
tolnay_beck %>%
count(year)
tolnay_beck %>%
count(year) %>%
summarize(sum(n))
tolnay_beck %>%
select(year, status_clean) %>%
group_by(year) %>%
count(status_clean) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
labs(title = "Actual, Threatened Lynchings, 1865-2020",
subtitle = "Count of Actual, Probable Lynchings. Tolnay-Beck Data",
caption = "n=5,871 incidents (lynchings = 5,039. Graphic by (redacted - peer review), 4/14/2023",
y="Count",
x="Year")
tolnay_beck %>%
select(year, status_clean) %>%
group_by(year) %>%
count(status_clean) |>
summarize(sum(n))
tolnay_beck %>%
#select(year, status_clean) %>%
#group_by(year) %>%
count(status_clean) |>
summarize(sum(n))
View(tolnay_beck)
tolnay_beck %>%
filter(status_clean =="lynching") |>
count(status_clean) |>
summarize(sum(n))
tolnay_beck %>%
filter(status_clean =="lynching") |>
count(year) %>%
summarize(sum(n))
tolnay_beck %>%
filter(status_clean =="lynching") |>
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1860, 2020, 10)), breaks = seq(1860, 2020, 10)) +
labs(title = "Actual Lynchings, 1865-2020",
subtitle = "Count of Actual Lynchings. Tolnay-Beck Data",
caption = "n=5,039 lynchings. Graphic by (redacted - peer review), 10/11/2024",
y="Count",
x="Year")
#Actual Lynchings Tolnay 4_14_2023
ggsave("../output_images_tables/Article_Images/Figure_4_tolnay_graphic_10_11_2024.png", dpi = 800, width = 10, height = 10)
View(main_index)
