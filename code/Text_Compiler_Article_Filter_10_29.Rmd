---
title: "Sean Text Compiler"
author: "Rob Wells"
date: "2023-10-29-23"
output: html_document
---
```{r}
library(tidyverse)
here::i_am("Text_Compiler_Article_Filter_10_29.rmd")

```


#Filtering and combining indexes
```{r}
#import old index of 1387 files
jackindex_march8 <- rio::import("../data/jackindex_march8.csv")

#import index of 1673 articles
jack_ORIGINAL_index <- read_csv("~/Code/hcij_lynching_phase_two/Storage_Older_Versions/article_text_2023-02-01_original_bak/LayoutBoxes_merged_20230123-162719_index.csv")

#import Oct 19 extraction index of 6507 articles (Aug 23: 3,385 articles)
#matches the number of articles in /Users/robwells/Code/hcij_lynching_phase_two/articles_10_19

jackindex_oct19 <- read_csv("../data/articles_10_19.csv")

```
# Fix URLs

```{r}
# Fix URLs

jackindex_oct19$url_fixed <- sub("sn\\d+/\\K.*", "", jackindex_oct19$URL, perl = TRUE)
jackindex_oct19$url_fixed <- sub("/$", "", jackindex_oct19$url_fixed)

#create date
jackindex_oct19 <- jackindex_oct19 %>% 
  mutate(date = paste(month,day,year, sep="/")) %>% 
  mutate(date = lubridate::mdy(date)) 

#date fixed for url
jackindex_oct19$date2 <- as.character(jackindex_oct19$date)
jackindex_oct19$date2 <- gsub("-", "/", jackindex_oct19$date2)


#create sequence column
# jackindex_oct19$seq <- sub(".*/(seq-\\d+).*", "\\1", jackindex_oct19$url)

jackindex_oct19 <- jackindex_oct19 %>% 
  mutate(url2 = paste(url_fixed, date2, edition, page, "0?user_id=6", sep="/")) 

jackindex_oct19 <- subset(jackindex_oct19, select =-URL)

jackindex_oct19 <- jackindex_oct19 %>% 
  rename(URL = url2) 

#write_csv(jackindex_oct19, "../data/jackindex_fixed_oct19.csv")



```


```{r}
#1090 files in the new index match the original. 
matched <-  jack_ORIGINAL_index %>% 
 inner_join(jackindex_oct19, by=c("file_id",  "article_id"))

#these are the 5417 new articles from the extraction 
new <-  jackindex_oct19 %>% 
 anti_join(jack_ORIGINAL_index, by=c("file_id",  "article_id"))

```


#Checking discrepancy between index and files
```{r}
#list of all 6507 articles in folder
folder_files <- list.files("/Users/robwells/Code/hcij_lynching_phase_two/articles_10_19/", pattern="*.txt") %>%
  as.data.frame() %>%
  rename(file_id = 1) %>% 
  mutate(index = 1:length(file_id)) 

#cut .txt
folder_files$file_id <- gsub(".txt", "", folder_files$file_id)

#merge the file_id in jackindex_aug23
jackindex_oct19 <- jackindex_oct19 %>% 
  mutate(file_id2 = (paste(file_id, article_id, sep = '_')))

#6507 files in the folder and the index
files_in <- jackindex_oct19 %>% 
  inner_join(folder_files, by=c("file_id2"="file_id"))

#0 files not in the folder but in the index
files_out <- jackindex_oct19 %>% 
  anti_join(folder_files, by=c("file_id2"="file_id"))

jackindex_oct19 <- jackindex_oct19 %>% 
  janitor::clean_names()

jackindex_oct19 <- jackindex_oct19 %>% 
  mutate(date = paste(month,day,year, sep="/")) %>% 
  mutate(date = lubridate::mdy(date)) 

jackindex_oct19 <- jackindex_oct19 %>% 
  select(file_id2, newspaper_name, newspaper_state, date, year, month, day, page, edition, mod_id, unnamed_0, file_id, article_id, sn, url)


#write_csv(jackindex_oct19, "../data/articles_10_19.csv")

```


```{r}
#Remove articles cleaned out previously
#this file shows the 281 articles dropped during my March 8 and July 17 cleaning process
anti_jack <- read.csv("../Output/dropped_articles_July_17.csv")
#clean this file
anti_jack <- anti_jack %>% 
 select(2:14)
#clean article_id
anti_jack$article_id <- gsub("-", "", anti_jack$article_id)
#merge the file_id 
anti_jack <- anti_jack %>% 
  mutate(file_id2 = (paste(file_id, article_id, sep = '_')))

#59 removed
cleaned_articles_oct19 <- jackindex_oct19 %>% 
  anti_join(anti_jack, by=c("file_id2"))
#new index is 6448 files


#Assign a black press designator
black_papers <- read_csv("../data/black_papers.csv") %>% 
  rename(newspaper_name = Title) %>% 
  as.data.frame()


black_papers1 <- black_papers %>% 
  mutate(black_press = "Y") %>% 
  select(newspaper_name, LCCN, black_press) %>% 
  distinct(LCCN, .keep_all = TRUE)

cleaned_articles_oct19 <- cleaned_articles_oct19 %>%
   left_join(black_papers1, by=c("sn"="LCCN")) %>% 
  rename(newspaper_name = newspaper_name.x) %>% 
  distinct(file_id2, .keep_all = TRUE)

df <- cleaned_articles_oct19[-c(17, 18, 19,20), ] 

# cleaned_articles_oct19 <- subset(cleaned_articles_oct19, select = - c(black_press.x, newspaper_name.y.y, black_press.y, newspaper_name.y))
cleaned_articles_oct19 <- subset(cleaned_articles_oct19, select = - c(newspaper_name.y))

#write.csv(cleaned_articles_oct19, "../output/cleaned_articles_index_urlfixed_oct19.csv")
```

```{r}

#This tutorial shows how to copy files from one directory to another
# https://stackoverflow.com/questions/68995687/r-move-files-to-folder-based-on-list-or-column

inputdir  <- "/Users/robwells/Code/hcij_lynching_phase_two/articles_10_19" 

#targetdir <- "/Users/robwells/Code/hcij_lynching_phase_two/narratives/code/articles_oct_19/" 

targetdir <- "/Users/robwells/Code/hcij_lynching_phase_two/narratives/data/articles_oct_19/" 

cleaned_articles_oct19 <- cleaned_articles_oct19 %>% 
   mutate(filename = paste(file_id2, ".txt", sep = ''))

#df <- extracted_articles_aug25$filename 

#creates new directory with 6448 articles: code/latest_articles/
filestocopy <- list.files(inputdir, full.names = TRUE) %>% 
  as_tibble() %>% 
  mutate(filename=(sub(".*/", "", value))) %>% 
  inner_join(cleaned_articles_oct19 , by=c("filename")) 
  #create a new column mutate = string-extract. keep everything after the last slash
  #inner_join to extracted articles aug 25
vector <- filestocopy$value
  #take that file path, select only filepath column and turn into a vector
  
filetocopy <- filestocopy[[1]]
#df_single <- df[[1]]
file.copy(from = filetocopy, to = targetdir)
map(vector, ~file.copy(from = inputdir, to=targetdir))

#map(filestocopy, ~file.copy(from = ., to=targetdir))


```


### Merge blackindex with cleaned_articles_oct19

```{r}
#714 articles from proquest and Howard, cleaned

blackindex <- read.csv("../output/blackindex_oct19.csv") %>% 
  mutate(black_press = "blackpress") %>% 
  mutate(date = lubridate::ymd(date))
#7162 articles
master_article_index_10.19 <- cleaned_articles_oct19 %>% 
  full_join(blackindex, by=c("file_id2"="file_name", "newspaper_name", "newspaper_state", "date", "year", "url", "filename", "black_press"))


#write.csv(master_article_index_10.19, "../data/master_article_index_10.19.csv")
```


```{r}
#years counted in new extraction

master_article_index_10.19 %>% 
  count(year) %>% 
  arrange(year)

#638 pre-Civil War articles
precivilwar <- master_article_index_10.19 %>% 
  filter(year < 1861) %>% 
  count(year) %>% 
  arrange(year)

sum(precivilwar$n)

```

### Sean's compiler of raw text. 
```{r include=FALSE}

#This was run once to compile the lynch object and "articles_1pct_dec26.csv" and then used for tokenizing, etc

#####################
# Begin SM Code #####
#####################

###
# List out text files that match pattern .txt, create DF
###
#previously 848 stories
# files <- list.files("../sample_corpus_1pct_article_text/", pattern="*.txt") %>%
#   as.data.frame() %>%
#   rename(filename = 1) %>%
#   filter(!str_detect(filename,"_bak"))
# # Loads 1,387 stories I reviewed and cleaned on March 8
# files <- list.files("~/Code/hcij_lynching_phase_two/articles_cleaned_2023_03_08", pattern="*.txt") %>% 

###
# Load 1,387 stories I reviewed and cleaned on March 8
# previously: Load 1,466  stories provided by jack, create join column, join to files list (previously 848 stories)
#Previous index: jackindex <- read_csv("../sample_corpus_1pct_article_text/stratified_sample_manifest.csv")
###

#Loads the 2246 files from July 16
# files <- list.files("~/Code/hcij_lynching_phase_two/articles_july_16", pattern="*.txt") %>% 
#   as.data.frame() %>%
#   rename(filename = 1) %>%
#   filter(!str_detect(filename,"_bak"))

files <- list.files("~/Code/hcij_lynching_phase_two/narratives/code/articles_oct_19", pattern="*.txt") %>% 
  as.data.frame() %>%
  rename(filename = 1) 



# jackindex <- rio::import("../data/july_16_article_index.csv") %>%
#   mutate(filename = paste0(file_id,"_",article_id,".txt")) %>%
#   inner_join(files) %>%
#   mutate(filepath = paste0("/Users/robwells/Code/hcij_lynching_phase_two/articles_july_16/",filename))

jackindex <- cleaned_articles_oct19 %>% 
  mutate(filepath = paste0("~/Code/hcij_lynching_phase_two/narratives/data/articles_oct_19/",filename))


#The data is here
#https://github.com/Howard-Center-Investigations/hcij_lynching_phase_two/blob/main/article_text_7_15/article_text_2022-07-14.tar.gz

###
# Define function to loop through each text file referenced in jackindex df
###

create_article_text <- function(row_value) {
  
  #row_value is the single argument that is passed to the function
  # Take each row of the dataframe
  temp <- jackindex %>%
    slice(row_value)
  
  # Store the filename for  use in constructing articles dataframe
  temp_filename <- temp$filename
  
  # Create a dataframe by reading in lines of a given textfile
  # Add a filename column 
  articles_df_temp <- read_lines(temp$filepath) %>%
    as_tibble() %>%
    mutate(filename = temp_filename)
  
  # Bind results to master articles_df
  # <<- returns to global environment
  articles_df <<- articles_df %>%
    bind_rows(articles_df_temp)
}

###
# Create elements needed to run function
###

# Create empty tibble to store results
articles_df <- tibble()
#running once to test
#create_article_text(2) 
# Create an array of numbers to loop through, from 1 to the number of rows in our index dataframe 
row_values <- 1:nrow(jackindex)

###
# Execute function using lapply
# This loops through each row of the dataframe and append results to master file
###

lapply(row_values, create_article_text)

# Error: The size of the connection buffer (131072) was not large enough
# to fit a complete line:
# * Increase it by setting `Sys.setenv("VROOM_CONNECTION_SIZE")`
#https://github.com/tidyverse/vroom/issues/364
#Sys.setenv(VROOM_CONNECTION_SIZE = 10000000)


###
# Clean up articles_df and join to index dataframe
###

articles_df <- articles_df %>%
  select(filename, sentence=value) %>%
  inner_join(jackindex)

#write.csv(articles_df, "../data/articles_oct_19.csv")

#####################
# End SM Code #####
#####################

# write.csv(articles_df, "articles_july_16.csv")
# lynch <- articles_df
# write_csv(jackindex, "jackindex_july16.csv")
```


# Notes

# finding the articles dropped from the index due to March 8 cleaning
```{r}
# jack_ORIGINAL_index <- read_csv(here:here("~/Code/hcij_lynching_phase_two/Storage_Older_Versions/article_text_2023-02-01_original_bak/LayoutBoxes_merged_20230123-162719_index.csv"))

jack_ORIGINAL_index <- read_csv("~/Code/hcij_lynching_phase_two/Storage_Older_Versions/article_text_2023-02-01_original_bak/LayoutBoxes_merged_20230123-162719_index.csv")

anti_jack <- jack_ORIGINAL_index %>% 
  anti_join(jackindex, by=("file_id")) %>% 
  distinct()

anti_jack %>% 
  count(file_id) %>% 
  arrange(desc(n))

#this file shows the 286 articles dropped during my March 8 cleaning process: 1673 articles in jack Feb 2 index down to 1387 articles now
#write.csv(anti_jack, "~/Code/hcij_lynching_phase_two/dropped_articles_march_8.csv")

```

#121 articles do not match the original list
excluded<- jackindex_march8 %>% 
  anti_join(jackindex_july16, by=c("file_id", "article_id")) %>% 
  distinct()

#1432 articles on new list not on old list
excluded1 <- jackindex_july16 %>% 
  anti_join(jackindex_march8, by=c("file_id", "article_id")) %>% 
  distinct()

#1182 articles on new list not on pre-March8 list
excluded2 <- jackindex_july16 %>% 
  anti_join(jack_ORIGINAL_index, by=c("file_id", "article_id")) %>% 
  distinct()

#160 articles on old list not on new July 16 list
excluded3 <- jack_ORIGINAL_index %>% 
  anti_join(jackindex_july16, by=c("file_id",  "article_id"))

# excluded3 <- jack_ORIGINAL_index %>% 
#   anti_join(jackindex_july16, by=c("file_id", "article_id")) %>% 
#   distinct()

#test - pre-march and march 8 correctly show 286 articles cut from new list
excluded5 <- jack_ORIGINAL_index %>% 
  anti_join(jackindex_march8, by=c("file_id",  "article_id"))
