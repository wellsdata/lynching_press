---
title: "Bigram Analysis"
author: "(redacted for peer review)"
date: '2024-7-2'
output: html_document
---

```{r}
library(tidyverse)
#install.packages("tidytext")
library(tidytext)
library(rio)
#install.packages("quanteda") 
library(quanteda)
```
#Import extracted data
```{r}
 

lynch <- read_csv("https://osf.io/download/fnzkt/?view_only=6c106acd6cb54f6f849e8c6f9098809f")


bp_text <- read.csv("https://osf.io/download/4m9zc/?view_only=6c106acd6cb54f6f849e8c6f9098809f")


#1045 BP articles
x <- bp_text %>% 
  distinct(filename)
#total 1,045 articles from the black press

#6448 white press articles
y <- lynch %>% 
  distinct(filename)
```


# plot of years covered
```{r}

#Note: iterate the same workflow with the lynch df for all decades

#Range of years covered
years_ct <- bp_text %>%
  distinct(filename, .keep_all = TRUE) %>% 
  count(year)

y <- bp_text %>%
  distinct(filename, .keep_all = TRUE)


```
# By decade

## pre1900
```{r}
pre1900 <- bp_text %>% 
  filter(year < 1900)

pre1900 %>% 
  select(filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#88 articles prior to 1900

statespre1900 <- pre1900 %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statespre1900 %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)

# Strong Southern representation
# Alabama	32			
# Virginia	20			
# District of Columbia	12			
# Iowa	10			
# Illinois	6			
# North Carolina	3			
# Louisiana	2			
# Michigan	1			
# New_York	1			
# Oklahoma	1	

#Fact Check
#sum(statespre1850s$n)
x <- pre1900 %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/pre1850s_index.csv")
```
## 1900s

```{r}
the1900s <-  bp_text %>% 
  filter(year >= 1900 & year <=1909)

the1900s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#17 articles in 1900s

statesthe1900s <- the1900s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1900s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=15)
# Colorado	5			
# Illinois	5			
# Iowa	2			
# District of Columbia	1			
# New_York	1			
# Oklahoma	1			
# Washington	1			
# West Virginia	1		

#Fact Check
#sum(statesthe1900s$n)

x <- the1900s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1900s_index.csv")
```

## 1910s

```{r}
the1910s <-  bp_text %>% 
  filter(year >= 1910 & year <=1919)

the1910s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#119 articles 

statesthe1910s <- the1910s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1910s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)

#newspaper_state: Looks like the Defender is active

# Illinois	40			
# Nebraska	30			
# Arizona	9			
# Colorado	8			
# Pennsylvania	8			
# Ohio	4			
# West Virginia	4			
# Wisconsin	4			
# Minnesota	3			
# Washington	3

#Fact Check
#sum(statesthe1850s$n)

x <- the1910s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1910s_index.csv")
```

##1920s

```{r}
the1920s <-  bp_text %>% 
  filter(year >= 1920 & year <=1929)

the1920s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#165 articles 

statesthe1920s <- the1920s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1920s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state: Defender and Courier

# Illinois	40			
# Pennsylvania	39			
# Virginia	23			
# Nebraska	15			
# New_York	14			
# Arizona	13			
# Colorado	6			
# Oklahoma	5			
# Texas	5			
# Washington	3	

#Fact Check
#sum(statesthe1850s$n)

x <- the1920s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1920s_index.csv")
```
##1930s

```{r}
the1930s <-  bp_text %>% 
  filter(year >= 1930 & year <=1939)

the1930s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#826 articles 

statesthe1930s <- the1930s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1930s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Wisconsin	62			
# Minnesota	61			
# Kansas	51			
# Ohio	48			
# Mississippi	36			
# Montana	36			
# Kentucky	35			
# Alabama	33			
# Georgia	30			
# Tennessee	26	

#Fact Check
#sum(statesthe1850s$n)

x <- the1930s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

write_csv(x, "../output/the1930s_index.csv")
```
##1890s

```{r}
the1890s <-  bp_text %>% 
  filter(year >= 1890 & year <=1899)

the1890s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#1637 articles 

statesthe1890s <- the1890s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1890s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Kansas	115			
# Wisconsin	102			
# Missouri	86			
# Kentucky	83			
# Minnesota	83			
# North Dakota	75			
# Georgia	73			
# South Dakota	71			
# North Carolina	57			
# Mississippi	54	

#Fact Check
#sum(statesthe1850s$n)

x <- the1890s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1890s_index.csv")
```

##1900s

```{r}
the1900s <-  bp_text %>% 
  filter(year >= 1900 & year <=1909)

the1900s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#1627 articles 

statesthe1900s <- the1900s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1900s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Wisconsin	88			
# Mississippi	87			
# Nebraska	83			
# Missouri	77			
# Utah	76			
# Arkansas	72			
# North Carolina	69			
# South Dakota	66			
# Kentucky	64			
# Alabama	62		

#Fact Check
#sum(statesthe1850s$n)

x <- the1900s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1900s_index.csv")
```
##1910s

```{r}
the1910s <-  bp_text %>% 
  filter(year >= 1910 & year <=1919)

the1910s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#840 articles 

statesthe1910s <- the1910s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1910s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Alaska	85			
# Arkansas	68			
# Nebraska	56			
# Illinois	41			
# Alabama	34			
# Wisconsin	29			
# North Dakota	27			
# Colorado	23			
# Texas	23			
# West Virginia	23			

#Fact Check
#sum(statesthe1850s$n)

x <- the1910s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

write_csv(x, "../output/the1910s_index.csv")
```

##1920s

```{r}
the1920s <-  bp_text %>% 
  filter(year >= 1920 & year <=1929)

the1920s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#357 articles 

statesthe1920s <- the1920s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1920s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Alaska	60			
# Illinois	34			
# Wyoming	22			
# Nebraska	19			
# Arizona	15			
# Oklahoma	14			
# District of Columbia	12			
# North Dakota	12			
# Texas	12			
# Montana	11			

#Fact Check
#sum(statesthe1850s$n)

x <- the1920s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

write_csv(x, "../output/the1920s_index.csv")
```

##1930s
```{r}
the1930s <-  bp_text %>% 
  filter(year >= 1930 & year <=1939)

the1930s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#309 articles 

statesthe1930s <- the1930s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1930s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Pennsylvania	102			
# Virginia	48			
# Georgia	46			
# Illinois	42			
# New_York	29			
# Nebraska	12			
# Washington	11			
# Ohio	9			
# Michigan	5			
# California	3			
		

#Fact Check
#sum(statesthe1850s$n)

x <- the1930s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1930s_index.csv")
```

## 1940s
```{r}
the1940s <-  bp_text %>% 
  filter(year >= 1940 & year <=1949)

the1940s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#250 articles 

statesthe1940s <- the1940s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1940s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Georgia	61			
# Pennsylvania	48			
# Illinois	38			
# Ohio	24			
# Virginia	22			
# Michigan	18			
# Minnesota	17			
# New_York	11			
# California	5			
# Nebraska	4	

#Fact Check
#sum(statesthe1850s$n)

x <- the1940s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1940s_index.csv")
```

## 1950s
```{r}
the1950s <-  bp_text %>% 
  filter(year >= 1950 & year <=1959)

the1950s %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#49 articles 

statesthe1950s <- the1950s %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statesthe1950s %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Illinois	13			
# Georgia	11			
# New_York	7			
# Pennsylvania	6			
# Virginia	6			
# California	3			
# Ohio	3	

#Fact Check
#sum(statesthe1850s$n)

x <- the1950s %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/the1950s_index.csv")
```
## post1960
```{r}
post1960 <-  bp_text %>% 
  filter(year >= 1960)

post1960 %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#48 articles 

statespost1960 <- post1960 %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

statespost1960 %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)
#newspaper_state

# Pennsylvania	13			
# Illinois	9			
# New_York	7			
# California	5			
# Georgia	4			
# Ohio	4			
# Virginia	4			
# Arizona	1			
# Minnesota	1	

#Fact Check
#sum(statesthe1850s$n)

x <- post1960 %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  arrange(date)

#write_csv(x, "../output/post1960_index.csv")
```

# Tokenize
### iterate for each decade
```{r}

stories <- str_replace_all(post1960$sentence, "- ", "")
stories_df <- tibble(stories,)

# unnest includes lower, punct removal

stories_tokenized <- stories_df %>%
  unnest_tokens(word,stories)

stories_tokenized

#Remove stopwords

data(stop_words)

stories_tokenized <- stories_tokenized %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(word != "temp_file") %>%
  filter(word != "stories_corpus") %>%
  filter(!grepl('[0-9]', word))

# fix the script so it doesn't pick up these file names, numbers  
# forcibly removing for now


# Word Count

story_word_ct <- stories_tokenized %>%
  count(word, sort=TRUE)

#write_csv(bp_text_word_ct, "lynching_corpus_word_count.csv")

```



# Bigrams

```{r}
stories_bigrams <- stories_df %>%
  unnest_tokens(bigram, stories, token="ngrams", n=2)

stories_bigrams

#Filter out stop words.


stories_bigrams_separated <- stories_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

stories_bigrams_filtered <- stories_bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

stories_bigram_cts <- stories_bigrams_filtered %>%
  count(word1, word2, sort = TRUE)

# put back into bigram form if we want to use them
stories_bigrams_united <- stories_bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

#replace Date for the decade analyzed
stories_bigram_cts_post1960 <- stories_bigram_cts %>% 
  mutate(decade = "post1960")

write_csv(stories_bigram_cts_post1960, "../output/bp_post1960_lynch_bigram_count.csv")

```

# Trigrams

```{r}
stories_trigrams <- stories_df %>%
  unnest_tokens(trigram, stories, token="ngrams", n=3)

stories_trigrams_separated <- stories_trigrams %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ")

stories_trigrams_ct <- stories_trigrams_separated %>%
  count(word1, word2, word3, sort = TRUE)

#filtered
# stories_trigrams_filtered <- stories_trigrams_separated %>%
#   filter(!word1 %in% stop_words$word) %>%
#   filter(!word2 %in% stop_words$word) %>%
#   filter(!word3 %in% stop_words$word)
# 
# stories_trigrams_ct <- stories_trigrams_filtered %>%
#   count(word1, word2, word3, sort = TRUE)

#replace Date for the decade analyzed
stories_trigrams_ct_post1940 <- stories_trigrams_ct %>% 
  mutate(decade = "post1940")

write_csv(stories_trigrams_ct_post1940, "../output/post1940_lynch_trigram_count.csv")


```

#Compile DFs 

```{r}
#Compile DFs

bigrams_all <- rbind(stories_bigram_cts_pre1900, stories_bigram_cts_the1900s, stories_bigram_cts_the1910s,stories_bigram_cts_the1920s, stories_bigram_cts_the1930s, stories_bigram_cts_the1940s,stories_bigram_cts_the1950s,stories_bigram_cts_post1960) 


write.csv(bigrams_all, "../output/BP_all_bigrams_11.10.csv")
```


#Analysis
# Analyzing the Black press

```{r}

black_bigrams <- read_csv("../output/bp_bigrams/BP_all_bigrams_11.15.csv") 

black_bigrams_pre_1900 <- read_csv("../output/bp_bigrams/bp_pre1900_lynch_bigram_count.csv") 

black_bigrams %>%
  filter(n >= 5) %>%
  filter(decade == "1930s") %>% 
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))


black_bigrams %>%
  filter(n >= 5) %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams <- black_bigrams %>%
  na.omit()

bigrams_for_viz <- black_bigrams %>%
  mutate(black_bigrams, x = paste(word1, word2)) 

#write_csv(bigrams_for_viz, "bigrams_for_viz.csv")

# comparing to the white press

white_bigrams <- read_csv("../output/all_bigrams_11.10.csv")

white_bigrams %>%
  filter(str_detect(word1, 'jim') & str_detect(word2, 'crow'))

white_bigrams %>%
  filter(str_detect(word1, 'civil') & str_detect(word2, 'rights'))

white_bigrams %>%
  filter(decade == "1930") %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

white_bigrams_for_viz <- white_bigrams %>%
  mutate(white_bigrams, x = paste(word1, word2)) 

#write_csv(white_bigrams_for_viz, "white_bigrams_viz.csv")

white_bigrams %>%
  filter(n >= 5) %>%
  filter(decade == "1930") %>%
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))

black_bigrams %>%
  filter(decade == '1910s')

black_bigrams %>%
  filter(decade == '1920s')

black_bigrams %>%
  filter(decade == '1930s')

black_bigrams %>%
  filter(decade == '1940s')

white_bigrams %>%
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))

black_bigrams %>%
  filter(str_detect(word1, 'jim') & str_detect(word2, 'crow'))

white_bigrams %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams %>%
  filter(decade == "1930s") %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams %>%
  filter(str_detect(word1, 'civil') & str_detect(word2, 'rights'))

```


```{r}
black_bigrams %>%
  filter(n >= 5) %>%
  filter(decade == "1930s") %>% 
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))


black_bigrams %>%
  filter(n >= 5) %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams <- black_bigrams %>%
  na.omit()

bigrams_for_viz <- black_bigrams %>%
  mutate(black_bigrams, x = paste(word1, word2)) 

#write_csv(bigrams_for_viz, "bigrams_for_viz.csv")

# comparing to the white press

white_bigrams <- read_csv("../output/all_bigrams_11.10.csv")

white_bigrams %>%
  filter(str_detect(word1, 'jim') & str_detect(word2, 'crow'))

white_bigrams %>%
  filter(str_detect(word1, 'civil') & str_detect(word2, 'rights'))

white_bigrams %>%
  filter(decade == "1930") %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

white_bigrams_for_viz <- white_bigrams %>%
  mutate(white_bigrams, x = paste(word1, word2)) 

#write_csv(white_bigrams_for_viz, "white_bigrams_viz.csv")

white_bigrams %>%
  filter(n >= 5) %>%
  filter(decade == "1930") %>%
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))

black_bigrams %>%
  filter(decade == '1910s')

black_bigrams %>%
  filter(decade == '1920s')

black_bigrams %>%
  filter(decade == '1930s')

black_bigrams %>%
  filter(decade == '1940s')

white_bigrams %>%
  filter(str_detect(word1, 'mob') & str_detect(word2, 'violence'))

black_bigrams %>%
  filter(str_detect(word1, 'jim') & str_detect(word2, 'crow'))

white_bigrams %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams %>%
  filter(decade == "1930s") %>%
  filter(str_detect(word1, 'anti') & str_detect(word2, 'lynching'))

black_bigrams %>%
  filter(str_detect(word1, 'civil') & str_detect(word2, 'rights'))

```



