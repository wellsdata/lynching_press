unarmed_black_women_final
#26.92% of black women were among the unarmed females who were fatally shot. the discrepancy from 28 percent is likely because the data from github was last updated in 2022, so there have been updated shooting since then.
#We are first answering how many individuals were armed when they were fatally shot. We started with filtering the data by gender. We also filtered by the y/m/d to ensure that we had the same exact numbers as the article.
#We are trying to figure out the armed status of individuals fatally shot: **As with fatal police shootings of men, the vast majority of the women killed were armed with a potential weapon at the time, although slightly less often: 89 percent of the women were armed, compared to 91 percent of the men.**
#Determining who was armed
armed_unarmedf <- police_shooting_women %>%
mutate(
in_out = case_when(
armed == 'unarmed' ~ "unarmed",
armed != 'unarmed' ~ "armed",
)
armed_unarmedf %>%
count(in_out)
222/(222+26)
armed_unarmedm <- police_shooting_men %>%
mutate(
in_out =case_when(
armed == 'unarmed'~"unarmed",
armed != 'unarmed' ~ "armed",
)
armed_unarmedm %>%
count(in_out)
5009/(5009+351)
#With this analysis we are making one key assumption: that every individiual that is not unarmed is armed. This is sorting blanks and undetermined weapons into the armed category, which might slightly skew our data. However the result that we get through this data yields 89%, which is what is described in the data.The male data was slightly off - with our results yielding 93% compared to the 91% described in the article. The Github was last updated in 2022, which is the likely reason why there is a discrepancy in the data
#We are now answering the question of the mental health status of women and men. This is the finding we are trying to recreate: **About 31 percent, or 77, of the 247 women fatally shot by police since 2015 had mental health issues, compared to 22 percent of the 5,362 men killed.**
police_shooting_women %>%
count(signs_of_mental_illness)
83/(165+83)
#This yielded a result of 33% which is close to the results, and the discrepancy in numbers between 77 and 83 are likely due to the updated data in Github.
police_shooting_men %>%
count(signs_of_mental_illness)
1244/(4116+1244)
#This result yielded a very close result of 23% compared to the 22% mentioned in the article. This discrepancy is likely from the updated data in Github.
library(janitor)
library(tidyverse)
library(sf)
library(leaflet)
baltimore_homicides <- read_rds("data/baltimore_homicides.rds") %>%
clean_names()
baltimore_demographics <- read_rds("data/baltimore_tract_demographics.rds") %>%
clean_names()
baltimore_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds") %>%
clean_names()
#create values for majority white areas
majority_white_balt <- baltimore_demographics %>%
mutate(pct_white = (white_pop/total_pop)*100) %>%
mutate(neighborhood_dem = case_when(
pct_white > 50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
view(majority_white_balt)
#now, let's filter for majority white areas
filtered_majority_white <- majority_white_balt %>%
filter(neighborhood_dem == "majority_white")
view(filtered_majority_white)
#spatial joining
shootings_by_neighborhood <- baltimore_homicides %>%
st_join(majority_white_tracts) %>%
as_tibble()
case_status_by_neighborhood <- shootings_by_neighborhood %>%
group_by(neighborhood_type,disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(total_shootings = closed_by_arrest+closed_without_arrest+open_no_arrest) %>%
mutate(unsolved = open_no_arrest + closed_without_arrest) %>%
mutate(pct_unsolved = unsolved/total_shootings*100)
#spatial joining
shootings_by_neighborhood <- baltimore_homicides %>%
#  st_join(majority_white_tracts) %>%
st_join(majority_white_balt) %>%
as_tibble()
baltimore_homicides <- read_rds("data/baltimore_homicides.rds")
baltimore_tract_demo <- read_rds("data/baltimore_tract_demo.rds")
baltimore_tract_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
#assign each tract as either over or under 50% white (majority white)
majority_white <- baltimore_tract_demo %>%
mutate(pct_white = white_pop/total_pop) %>%
select(geoid, name, pct_white) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
#join majority_white data with Baltimore tract shapefiles and convert to spatial object
majority_white <- majority_white %>%
inner_join(baltimore_tract_shapefiles) %>%
st_as_sf()
#assign each shooting to a tract with a spatial join
neighborhood_shootings <- baltimore_homicides %>%
st_join(majority_white) %>%
as_tibble()
balt_homicides <- read_rds("data/baltimore_homicides.rds")
balt_tract_demographics <- read_rds("data/baltimore_tract_demographics.rds")
balt_tract_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
balt_maj_white <- baltimore_tract_demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority white",
TRUE ~ "non majority white"))
balt_maj_white_geo <- balt_maj_white %>%
inner_join(baltimore_tract_shapefiles) %>%
st_as_sf() %>%
st_join(baltimore_homicides) %>%
as_tibble()
ggplot() +
geom_sf(data=baltimore_tract_shapefiles) +
geom_sf(data=baltimore_homicides)
dispos_balt_maj_white_geo <- balt_maj_white_geo %>%
group_by(neighborhood_type, disposition) %>%
count(neighborhood_type, disposition) %>%
clean_names()
sum(dispos_balt_maj_white_geo$closed_by_arrest) = 1002
homicides <- read_rds("data/baltimore_homicides.rds")
demographics <- read_rds("data/baltimore_tract_demographics.rds")
shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
ggplot() +
geom_sf(data=shapefiles) +
geom_sf(data=homicides)
majority_white <- demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority white",
TRUE ~ "non majority white"))
balt_maj_white_geo <- majority_white %>%
inner_join(shapefiles) %>%
st_as_sf() %>%
st_join(homicides) %>%
as_tibble()
dispos_balt_maj_white_geo <- balt_maj_white_geo %>%
group_by(neighborhood_type, disposition) %>%
count(neighborhood_type, disposition)
dispos_balt_maj_white_geo <- dispos_balt_maj_white_geo %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(total = closed_by_arrest+closed_without_arrest+open_no_arrest) %>%
mutate(unsolved = open_no_arrest + closed_without_arrest) %>%
mutate(pct_unsolved = unsolved/total*100)
###
# Classify each tract as majority white or not
###
majority_white_tracts <- baltimore_tract_demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
select(geoid,name,pct_white) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
baltimore_homicides <- read_rds("data/baltimore_homicides.rds")
baltimore_tract_demographics <- read_rds("data/baltimore_tract_demographics.rds")
baltimore_tract_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
###
# Classify each tract as majority white or not
###
majority_white_tracts <- baltimore_tract_demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
select(geoid,name,pct_white) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
###
# Connect classified neighborhood file to spatial data
###
majority_white_tracts <- majority_white_tracts %>%
inner_join(baltimore_tract_shapefiles) %>%
st_as_sf()
###
# Spatial join to assign each shooting to a tract
###
shootings_by_neighborhood <- baltimore_homicides %>%
st_join(majority_white_tracts) %>%
as_tibble()
###
# Calculate the percentage of unsolved homicides in white and non-white neighborhoods
###
case_status_by_neighborhood <- shootings_by_neighborhood %>%
group_by(neighborhood_type,disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(total_shootings = closed_by_arrest+closed_without_arrest+open_no_arrest) %>%
mutate(unsolved = open_no_arrest + closed_without_arrest) %>%
mutate(pct_unsolved = unsolved/total_shootings*100)
case_status_by_neighborhood
###
# Output map
###
ggplot() +
geom_sf(data=baltimore_tract_shapefiles) +
geom_sf(data=baltimore_homicides)
View(case_status_by_neighborhood)
baltimore_homicides <- read_rds("data/baltimore_homicides.rds") %>%
clean_names()
baltimore_tracts <- read_rds("data/baltimore_tract_shapefiles.rds") %>%
clean_names()
baltimore_tract_demographics <- read_rds("data/baltimore_tract_demographics.rds") %>%
clean_names()
#determine what is a majority white area
majority_white_tracts <-baltimore_tract_demographics %>%
mutate(pct_white= (white_pop/total_pop*100)) %>%
select(geoid, name, pct_white) %>%
mutate(neighborhood_dem = case_when(
pct_white >50 ~ "majority_white",
TRUE ~ "not_majoritywhite"
))
#Join the newly created data set with baltimore tracts, and then combine taht data set with baltimore homicides.
majority_white_tracts <- majority_white_tracts %>%
inner_join(baltimore_tracts) %>%
st_as_sf
homicides_by_neighborhood <- baltimore_homicides %>%
st_join(majority_white_tracts) %>%
as_tibble()
#We are then creating a table that reorganizes the values into columns rather than rows that allows us to more easily mutate a column.
homicides_by_neighborhood %>%
group_by(neighborhood_dem, disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(totalshootings= closed_by_arrest, closed_without_arrest, open_no_arrest) %>%
mutate(unsolved_cases = closed_without_arrest, open_no_arrest) %>%
mutate(pct_unsolvedcases= (unsolved_cases/totalshootings)*100)
cases_neighborhood
#We are then creating a table that reorganizes the values into columns rather than rows that allows us to more easily mutate a column.
homicides_by_neighborhood %>%
group_by(neighborhood_dem, disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(totalshootings= closed_by_arrest, closed_without_arrest, open_no_arrest) %>%
mutate(unsolved_cases = closed_without_arrest, open_no_arrest) %>%
mutate(pct_unsolvedcases= (unsolved_cases/totalshootings)*100)
cases_neighborhood
ggplot() +
geom_sf(data=majority_white_tracts) +
geom_sf(data=baltimore_homicides, color="red")
baltimore_homicides <- read_rds("data/baltimore_homicides.rds")
baltimore_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
baltimore_demographics <- read_rds("data/baltimore_tract_demographics.rds")
baltimore_homicides_sf <- st_as_sf(baltimore_homicides)
joined_data <- st_join(baltimore_homicides_sf, baltimore_shapefiles)
joined_data <- joined_data %>%
st_drop_geometry()
final_data <- joined_data %>%
inner_join(baltimore_demographics, by = c("geoid", "name")) %>%
mutate(pct_white = (white_pop / total_pop) * 100) %>%
mutate(majority_minority_white = case_when(
pct_white > 50 ~ "majority_white",
pct_white < 50 ~ "minority_white"
))
solve_rates <- final_data %>%
group_by(majority_minority_white, disposition) %>%
count() %>%
pivot_wider(names_from = disposition, values_from = n) %>%
clean_names() %>%
mutate(total_shootings = closed_by_arrest + closed_without_arrest + open_no_arrest) %>%
mutate(solve_rate = (closed_by_arrest / total_shootings) * 100)
solve_rates %>%
ggplot(aes(x = majority_minority_white, y = solve_rate, fill = majority_minority_white)) +
geom_col(position = "dodge") +
labs(title = "Homicide Solve Rates by Race",
x = "Race",
y = "Solve Rate",
fill = "Majority or Minority White") +
theme_minimal()
baltimore_homicides <- read_rds("data/baltimore_homicides.rds")
baltimore_tract_demographics <- read_rds("data/baltimore_tract_demographics.rds")
baltimore_tract_shapefiles <- read_rds("data/baltimore_tract_shapefiles.rds")
majority_white <- baltimore_tract_demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
select(geoid,name,pct_white) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
majority_white <- majority_white %>%
inner_join(baltimore_tract_shapefiles) %>%
st_as_sf()
shootings <- baltimore_homicides %>%
st_join(majority_white_tracts) %>%
as_tibble()
arrest_status <- shootings %>%
group_by(neighborhood_type,disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(total_shootings = closed_by_arrest+closed_without_arrest+open_no_arrest) %>%
mutate(unsolved = open_no_arrest + closed_without_arrest) %>%
mutate(solved = closed_by_arrest/total_shootings*100)
majority_white <- baltimore_tract_demographics %>%
mutate(pct_white = white_pop/total_pop) %>%
select(geoid,name,pct_white) %>%
mutate(neighborhood_type = case_when(
pct_white > .50 ~ "majority_white",
TRUE ~ "not_majority_white"
))
majority_white <- majority_white %>%
inner_join(baltimore_tract_shapefiles) %>%
st_as_sf()
shootings <- baltimore_homicides %>%
st_join(majority_white_tracts) %>%
as_tibble()
View(shootings)
arrest_status <- shootings %>%
group_by(neighborhood_dem,disposition) %>%
count() %>%
pivot_wider(names_from=disposition, values_from=n) %>%
clean_names() %>%
mutate(total_shootings = closed_by_arrest+closed_without_arrest+open_no_arrest) %>%
mutate(unsolved = open_no_arrest + closed_without_arrest) %>%
mutate(solved = closed_by_arrest/total_shootings*100)
getwd()
setwd("~/Code/lynching_press/code")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "AIzaSyAg5IJmi9Ty0c44nO1sUcoWZKRMfwUP4Po")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#13,311 variables
#master_article_index_4_20 <- read.csv("../data/master_article_index_4_20.csv")
#945 articles
precivil_index <- master_article_index_4_20 %>%
filter(date < "1861-04-12") %>%
mutate(date = as_date(date))
#13,311 variables
master_article_index_4_20 <- read.csv("../data/master_article_index_4_20.csv")
precivil_index <- master_article_index_4_20 %>%
filter(date < "1861-04-12") %>%
mutate(date = as_date(date))
precivil <- rio::import("https://docs.google.com/spreadsheets/d/17nL8YBMIys7iJI1eeufiCpI1Plpmid2FSd6zuti5iSk/edit#gid=1208290507", skip=0)
precivil <- janitor::clean_names(precivil)
precivil <- precivil %>%
rename(lynching = 'y_n_describes_a_lynching') %>%
mutate(date = as_date(date))
precivil <- slice(precivil, -c(619,620))
precivil$id <- as.numeric(precivil$id)
View(master_article_index_4_20)
precivil <- rio::import("https://docs.google.com/spreadsheets/d/17nL8YBMIys7iJI1eeufiCpI1Plpmid2FSd6zuti5iSk/edit#gid=1208290507", which="precivil_new")
precivil <- janitor::clean_names(precivil)
precivil <- precivil %>%
rename(lynching = 'y_n_describes_a_lynching') %>%
mutate(date = as_date(date))
precivil <- precivil %>%
mutate(sn = str_extract(url, "(?<=/sn)\\d+"))
View(precivil)
names(precivil)
precivil <- rio::import("https://docs.google.com/spreadsheets/d/17nL8YBMIys7iJI1eeufiCpI1Plpmid2FSd6zuti5iSk/edit#gid=1208290507", which="precivil_new")
precivil <- rio::import("https://docs.google.com/spreadsheets/d/17nL8YBMIys7iJI1eeufiCpI1Plpmid2FSd6zuti5iSk/edit#gid=1208290507", sheet="precivil_new")
library(googlesheets4)
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/17nL8YBMIys7iJI1eeufiCpI1Plpmid2FSd6zuti5iSk/edit#gid=1208290507"
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()
precivil <- read_sheet(google_sheets_url, sheet = "precivil_new")
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url, sheet = "precivil_new")
precivil <- janitor::clean_names(precivil)
precivil <- precivil %>%
rename(lynching = 'y_n_describes_a_lynching') %>%
mutate(date = as_date(date))
precivil <- precivil %>%
mutate(sn = str_extract(url, "sn\\d+"))
View(precivil)
View(precivil_index)
precivil_replies <- precivil %>%
filter(lynching !=is.na)
precivil_replies <- precivil %>%
filter(lynching !==is.na)
precivil_replies <- precivil %>%
filter(!is.na(lynching))
precivil_replies <- precivil %>%
filter(lynching==!("NA")))
precivil_replies <- precivil %>%
filter(lynching!=("NA")))
precivil_replies <- precivil %>%
filter(lynching!="NA")
names(precivil_replies)
names(precivil_index)
glimpse(precivil_index)
glimpse(precivil_replies)
x<- precivil_index %>%
inner_join(precivil_replies, by=c("sn", "date", "newspaper_name"))
x<- precivil_index %>%
inner_join(precivil_replies, by=c("sn", "date"))
View(x)
x<- precivil_index %>%
inner_join(precivil_replies, by=c("sn", "date", "page"))
x<- precivil_index %>%
right_join(precivil_replies, by=c("sn", "date", "page"))
x<- precivil_index %>%
left_join(precivil_replies, by=c("sn", "date", "page"))
x<- precivil_index %>%
full_join(precivil_replies, by=c("sn", "date", "page"))
View(x)
x<- precivil_index %>%
full_join(precivil_replies, by=c("sn", "date", "page", "year"))
x %>% count(reviewed_by_te)
View(precivil_index)
glimpse(x)
names(x)
x<- precivil_index %>%
full_join(precivil_replies, by=c("sn", "date", "page", "year"))
%>%
x<- precivil_index %>%
full_join(precivil_replies, by=c("sn", "date", "page", "year")) %>%
select(4:13, 15,16,18,19,20,37:43,45:50)
write.csv(x, "../output/precivil_war_4_2024.csv")
write_csv(x, "../output/precivil_war_4_2024.csv")
write_csv(x, "../output_images_tables/precivil_war_4_2024.csv")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("tigris")
#install.packages("zoo")
library(tigris)
library(stringr)
library(janitor)
library(zoo)
library(lubridate)
library(readtext)
#13,311 variables
master_article_index_4_20 <- read.csv("../data/master_article_index_4_20.csv")
View(master_article_index_4_20)
master_article_index_4_20$date2 <- as.character(master_article_index_4_20$date)
master_article_index_4_20$date2 <- gsub("-", "/", master_article_index_4_20$date2)
View(master_article_index_4_20)
names(master_article_index_4_20)
master_article_index_4_20$url_fixed <- sub("sn\\d+/\\K.*", "", master_article_index_4_20$url2, perl = TRUE)
master_article_index_4_20 <- master_article_index_4_20 %>%
mutate(url_final = paste(url_fixed, date2, edition, page, "0?user_id=6", sep="/"))
View(master_article_index_4_20)
XX  <- subset(master_article_index_4_20 , select -c(X, x1, x, url2, url_fixed, abstract, store_id, pages))
XX  <- subset(master_article_index_4_20, select -c(X, x1, x, url2, url_fixed, abstract, store_id, pages))
XX  <- subset(master_article_index_4_20, select = -c(X, x1, x, url2, url_fixed, abstract, store_id, pages))
View(XX)
master_article_index_4_20 <- subset(master_article_index_4_20, select = -c(X, x1, x, url2, url_fixed, abstract, store_id, pages))
jackindex_oct19 <- jackindex_oct19 %>%
rename(url_backup = url, url = url_final)
master_article_index_4_20 <- master_article_index_4_20 %>%
rename(url_backup = url, url = url_final)
names(master_article_index_4_20)
write_csv(master_article_index_4_20, "../data/master_article_index_4_20.csv")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "AIzaSyAg5IJmi9Ty0c44nO1sUcoWZKRMfwUP4Po")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
library(googlesheets4)
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit#gid=1328431032"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
library(googlesheets4)
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit?usp=sharing"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
View(precivil)
precivil <- precivil %>%
mutate(date = ymd(date))
View(precivil)
library(googlesheets4)
#Importing 991 precivil war articles from Google Sheet
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit?usp=sharing"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
View(precivil)
precivil <- precivil %>%
mutate(date2 = as.date(date))
precivil <- precivil %>%
mutate(date2 = as_date(date))
precivil$date <- as.character(precivil$date2)
precivil$date <- gsub("-", "/", precivil$date)
View(precivil)
names(precivil)
precivil$url <- sub("sn\\d+/\\K.*", "", precivil$url_fixed_april_2024, perl = TRUE)
precivil <- precivil %>%
mutate(url2 = paste(url, date, edition.x, page, "0?user_id=6", sep="/"))
precivil$url <- sub("/$", "", precivil$url)
View(precivil)
precivil <- precivil %>%
mutate(url2 = paste(url, date, edition.x, page, "0?user_id=6", sep="/"))
View(precivil)
View(master_article_index_4_20)
count(precivil$edition.x)
precivil %>% count(edition.x)
103-61
names(precivil)
View(precivil)
precivil <- subset(precivil, select = -c(url_fixed_april_2024, file_id.y, newspaper_name.y, file_id.x, url))
precivil <- precivil %>%
rename(edition = edition.x, newspaper_name = newspaper_name.x, url = url_final, newspaper_city = newspaper_city.y, url_final = url2)
precivil <- precivil %>%
rename(edition = edition.x, newspaper_name = newspaper_name.x,  newspaper_city = newspaper_city.y, url_final = url2)
write_csv(precivil, "../data/precivil_4_23.csv")
