rename(url_backup = url, url = url_final)
master_article_index_4_20 <- master_article_index_4_20 %>%
rename(url_backup = url, url = url_final)
names(master_article_index_4_20)
write_csv(master_article_index_4_20, "../data/master_article_index_4_20.csv")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "AIzaSyAg5IJmi9Ty0c44nO1sUcoWZKRMfwUP4Po")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
library(googlesheets4)
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit#gid=1328431032"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
library(googlesheets4)
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit?usp=sharing"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
View(precivil)
precivil <- precivil %>%
mutate(date = ymd(date))
View(precivil)
library(googlesheets4)
#Importing 991 precivil war articles from Google Sheet
# Provide your Google Sheets URL
google_sheets_url <- "https://docs.google.com/spreadsheets/d/1CCUgAAHdaYbd0dHOvJUqfCJsZk29_zYgJd3zGVwY53I/edit?usp=sharing"
googlesheets4::gs4_deauth()
precivil <- read_sheet(google_sheets_url)
View(precivil)
precivil <- precivil %>%
mutate(date2 = as.date(date))
precivil <- precivil %>%
mutate(date2 = as_date(date))
precivil$date <- as.character(precivil$date2)
precivil$date <- gsub("-", "/", precivil$date)
View(precivil)
names(precivil)
precivil$url <- sub("sn\\d+/\\K.*", "", precivil$url_fixed_april_2024, perl = TRUE)
precivil <- precivil %>%
mutate(url2 = paste(url, date, edition.x, page, "0?user_id=6", sep="/"))
precivil$url <- sub("/$", "", precivil$url)
View(precivil)
precivil <- precivil %>%
mutate(url2 = paste(url, date, edition.x, page, "0?user_id=6", sep="/"))
View(precivil)
View(master_article_index_4_20)
count(precivil$edition.x)
precivil %>% count(edition.x)
103-61
names(precivil)
View(precivil)
precivil <- subset(precivil, select = -c(url_fixed_april_2024, file_id.y, newspaper_name.y, file_id.x, url))
precivil <- precivil %>%
rename(edition = edition.x, newspaper_name = newspaper_name.x, url = url_final, newspaper_city = newspaper_city.y, url_final = url2)
precivil <- precivil %>%
rename(edition = edition.x, newspaper_name = newspaper_name.x,  newspaper_city = newspaper_city.y, url_final = url2)
write_csv(precivil, "../data/precivil_4_23.csv")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("tigris")
#install.packages("zoo")
library(tigris)
library(stringr)
library(janitor)
library(zoo)
library(lubridate)
library(readtext)
extracted_article_index_5_16 <- read.csv("../data/may_16_2024_article_index.csv")
View(extracted_article_index_5_16)
master_article_index_4_20 <- read.csv("../data/master_article_index_4_20.csv")
View(master_article_index_4_20)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date = paste(year, month, day, sep="-"))
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date = paste(year, month, day, sep="-")) %>%
mutate(date = ymd(date))
glimpse(extracted_article_index_5_16)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date = paste(year, month, day, sep="-")) %>%
mutate(date = ymd(date)) %>%
mutate(day2 = case_when(
day=="1" ~ "01",
day=="2" ~ "02",
day=="3" ~ "03",
day=="4" ~ "04",
day=="5" ~ "05",
day=="6" ~ "06",
day=="7" ~ "07",
day=="8" ~ "08",
day=="9" ~ "09",
TRUE ~ day
))
glimpse(extracted_article_index_5_16)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date = paste(year, month, day, sep="-")) %>%
mutate(date = ymd(date)) %>%
mutate(day2 = case_when(
day==1 ~ "01",
day==2 ~ "02",
day==3 ~ "03",
day==4 ~ "04",
day==5 ~ "05",
day==6 ~ "06",
day==7 ~ "07",
day==8 ~ "08",
day==9 ~ "09",
TRUE ~ as.character(day)
))
url <- extracted_article_index_5_16$URL
# Function to correct single-digit days in the URL
correct_day_in_url <- function(url) {
# Extract the part of the URL that contains the date (YYYY/M/D)
url_parts <- str_split(url, "/")[[1]]
# Identify the indices for year, month, and day
year_index <- length(url_parts) - 5
month_index <- length(url_parts) - 4
day_index <- length(url_parts) - 3
# Correct the day part if it's a single digit
if (nchar(url_parts[day_index]) == 1) {
url_parts[day_index] <- str_pad(url_parts[day_index], width = 2, side = "left", pad = "0")
}
# Reconstruct the URL
corrected_url <- str_c(url_parts, collapse = "/")
return(corrected_url)
}
# Apply the function to the data frame
urls <- urls %>%
mutate(corrected_url = sapply(url, correct_day_in_url))
urls <- extracted_article_index_5_16$URL
# Function to correct single-digit days in the URL
correct_day_in_url <- function(url) {
# Extract the part of the URL that contains the date (YYYY/M/D)
url_parts <- str_split(url, "/")[[1]]
# Identify the indices for year, month, and day
year_index <- length(url_parts) - 5
month_index <- length(url_parts) - 4
day_index <- length(url_parts) - 3
# Correct the day part if it's a single digit
if (nchar(url_parts[day_index]) == 1) {
url_parts[day_index] <- str_pad(url_parts[day_index], width = 2, side = "left", pad = "0")
}
# Reconstruct the URL
corrected_url <- str_c(url_parts, collapse = "/")
return(corrected_url)
}
# Apply the function to the data frame
urls <- urls %>%
mutate(corrected_url = sapply(url, correct_day_in_url))
extracted_article_index_5_16$url_fixed <- sub("sn\\d+/\\K.*", "", extracted_article_index_5_16$URL, perl = TRUE)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date2 = case_when(
str_detect(date, "-" ~ "/",
TRUE ~date
)))
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date2 = case_when(
str_detect(date, "-") ~ str_replace(date, "-", "/"),
TRUE ~ date
))
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date1 = as.character(date)) %>%
mutate(date2 = case_when(
str_detect(date1, "-") ~ str_replace(date1, "-", "/"),
TRUE ~ date1
))
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(date1 = as.character(date)) %>%
mutate(date2 = case_when(
str_detect(date1, "-") ~ str_replace(date1, "-", "/"),
TRUE ~ date1
))
View(extracted_article_index_5_16)
extracted_article_index_5_16$date2 <- str_replace_all(extracted_article_index_5_16$date1, pattern=fixed('-'), replacement=fixed('/') )
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(url_final = paste(url_fixed, date2, edition, page, "0?user_id=6", sep="/"))
glimpse(extracted_article_index_5_16)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
mutate(url_final = paste(url_fixed, date2, edition, page, "0?user_id=6", sep="/")) %>%
subset(select = -c(url_fixed,date1,day2, X))
glimpse(extracted_article_index_5_16)
extracted_article_index_5_16 <- extracted_article_index_5_16 %>%
rename(url = url_final, url_backup = URL)
glimpse(extracted_article_index_5_16)
#june 17 2024
write_csv(extracted_article_index_5_16, "../data/extracted_article_index_5_16.csv")
years_5_17 <- extracted_article_index_5_16 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
View(years_5_17)
View(master_article_index_4_20)
years_4_20 <- master_article_index_4_20 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
rename(pct_whole_old = pct_whole, count_old = count) %>%   mutate(rank_old = dense_rank(desc(pct_whole_old)))
year_compare <- years_4_20 %>%
inner_join(years_5_17, by="year") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
View(year_compare)
#install.packages("here")
here::here()
library(tidyverse)
#install.packages("tidytext")
library(tidytext)
library(rio)
#install.packages("quanteda")
library(quanteda)
View(master_article_index_4_20)
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by=c("file_id"))
glimpse(master_article_index_4_20)
glimpse(extracted_article_index_5_16)
test <- extracted_article_index_5_16 %>%
inner_join(master_article_index_4_20, by=c("file_id"))
test <- extracted_article_index_5_16 %>%
right_join(master_article_index_4_20, by=c("file_id"))
test <- extracted_article_index_5_16 %>%
left_join(master_article_index_4_20, by=c("file_id"))
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by=c("file_id"))
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by="file_id")
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by="file_id", na_matches = "na")
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by = "file_id", na_matches = "na")
dups_extracted <- extracted_article_index_5_16[duplicated(extracted_article_index_5_16$file_id) | duplicated(extracted_article_index_5_16$file_id, fromLast = TRUE), ]
dups_master <- master_article_index_4_20[duplicated(master_article_index_4_20$file_id) | duplicated(master_article_index_4_20$file_id, fromLast = TRUE), ]
# Check for missing values in extracted_article_index_5_16
na_extracted <- sum(is.na(extracted_article_index_5_16$file_id))
# Check for missing values in master_article_index_4_20
na_master <- sum(is.na(master_article_index_4_20$file_id))
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by = "file_id", na_matches = "na")
master_article_index_4_20 <- read.csv("../data/master_article_index_4_20.csv") %>%
mutate(idcol = trimws(file_id))
#12597 extracted
extracted_article_index_5_16 <- read.csv("../data/may_16_2024_article_index.csv") %>%
mutate(idcol = trimws(file_id))
test <- extracted_article_index_5_16 %>%
anti_join(master_article_index_4_20, by = "idcol", na_matches = "na")
test <- master_article_index_4_20 %>%
anti_join(extracted_article_index_5_16, by = "idcol", na_matches = "na")
library(tidyverse)
here::i_am("Text_Compiler_Article_Filter_6_17.rmd")
#import old index of 1387 files
jackindex_march8 <- rio::import("../data/jackindex_march8.csv")
folder_files <- list.files("/Users/robwells/Code/lynching_press/data/articles_may_16_2024", pattern="*.txt") %>%
as.data.frame() %>%
rename(file_id = 1) %>%
mutate(index = 1:length(file_id))
#cut .txt
folder_files$file_id <- gsub(".txt", "", folder_files$file_id)
View(master_article_index_4_20)
files_in <- extracted_article_index_5_16 %>%
inner_join(folder_files, by=c("file_id2"="file_id"))
files_in <- master_article_index_4_20 %>%
inner_join(folder_files, by=c("file_id2"="file_id"))
files_out <- master_article_index_4_20 %>%
anti_join(folder_files, by=c("file_id2"="file_id"))
View(files_out)
glimpse(files_in)
files_in %>%
count(black_press)
View(files_in)
files_in %>%
count(black_press=="Y")
BP <- files_in %>%
filter(black_press=="Y")
BP <- files_in %>%
filter(black=="Y")
blackindex <- read.csv("../output/blackindex_oct19.csv") %>%
mutate(black_press = "blackpress") %>%
mutate(date = lubridate::ymd(date))
blackindex <- read.csv("../data/blackindex_3_9_2023.csv") %>%
mutate(black_press = "blackpress") %>%
mutate(date = lubridate::ymd(date))
blackindex <- read.csv("../data/blackindex_3_9_2023.csv")
View(blackindex)
blackindex <- read.csv("../data/blackindex_3_9_2023.csv") %>%
mutate(black_press = "blackpress") %>%
mutate(date = lubridate::dmy(date))
glimpse(blackindex)
blackindex <- read.csv("../data/blackindex_3_9_2023.csv") %>%
mutate(black_press = "blackpress") %>%
mutate(date = lubridate::dmy(Date))
blackindex <- read.csv("../data/blackindex_3_9_2023.csv") %>%
mutate(black_press = "blackpress") %>%
mutate(date = as.Date(Date))
#714 articles from proquest and Howard, cleaned
blackindex2 <- read.csv("../data/blackindex_master.csv")
View(blackindex2)
blackindex2 %>%
count(black_press)
blackindex2 <- read.csv("../data/blackindex_master.csv") %>%
filter(black_press =="Y")
glimpse(blackindex2)
blackindex2 <- read.csv("../data/blackindex_master.csv") %>%
filter(black_press =="Y") %>%
mutate(date2 = ymd(date))
glimpse(blackindex2)
blackindex2 <- read.csv("../data/blackindex_master.csv") %>%
filter(black_press =="Y") %>%
mutate(date = ymd(date))
glimpse(blackindex2)
View(files_in)
View(blackindex2)
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_id2"="file_name", "newspaper_name", "newspaper_state", "date", "year", "url", "filename", "black_press"))
glimpse(files_in)
glimpse(blackindex2)
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_id2"="file_name", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_id2"="file_name"))
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_id2"=="file_name", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_id2"=="file_name"))
files_in <- files_in %>%
mutate(file_name = paste0(idcol, "_", article_id))
master_article_index_6_17 <- files_in %>%
full_join(blackindex, by=c("file_name", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
head(master_article_index_4_20)
head(files_in)
files_in <- files_in %>%
mutate(across(c(newspaper_name, newspaper_state, date, url, black_press), trimws))
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id2" = "file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
glimpse(blackindex2)
glimpse(files_in)
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
files_in <- files_in %>%
mutate(file_name = paste0(idcol, "_", article_id)) %>%
mutate(date = ymd(date))
View(files_in)
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press"))
10735+714
View(master_article_index_6_17)
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press", "sn", "article_id"))
names(master_article_index_6_17)
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press", "sn", "article_id", "day", "page", "edition", "mod_id", "index", "article_title", "newspaper_city", "collection", "authors", "document_type", "issn", "find_a_copy", "start_page", "filepath", "black"))
files_in <- files_in %>%
mutate(file_name = paste0(idcol, "_", article_id)) %>%
mutate(date = ymd(date)) %>%
rename(index = index.y) %>%
subset(select = -c(index.x))
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press", "sn", "article_id", "day", "page", "edition", "mod_id", "index", "article_title", "newspaper_city", "collection", "authors", "document_type", "issn", "find_a_copy", "start_page", "filepath", "black"))
names(master_article_index_6_17)
View(master_article_index_6_17)
master_article_index_6_17 <- files_in %>%
full_join(blackindex2, by = c("file_id", "newspaper_name", "newspaper_state", "date", "year", "url", "black_press", "sn", "article_id", "day", "page", "edition", "mod_id", "index", "article_title", "newspaper_city", "collection", "authors", "document_type", "issn", "find_a_copy", "start_page", "filepath", "black")) %>%
subset(select = -c(month.y))
write.csv(master_article_index_6_17, "../data/master_article_index_6_17.csv")
#Remove articles cleaned out previously
#this file shows the 281 articles dropped during my March 8 and July 17 cleaning process
anti_jack <- read.csv("../Output/dropped_articles_July_17.csv")
#Remove articles cleaned out previously
#this file shows the 281 articles dropped during my March 8 and July 17 cleaning process
anti_jack <- read.csv("../data/dropped_articles_July_17.csv")
anti_jack <- anti_jack %>%
select(2:14)
#clean article_id
anti_jack$article_id <- gsub("-", "", anti_jack$article_id)
anti_jack <- anti_jack %>%
mutate(file_id2 = (paste(file_id, article_id, sep = '_')))
Xmaster_article_index_6_17 <- master_article_index_6_179 %>%
anti_join(anti_jack, by=c("file_id2"))
Xmaster_article_index_6_17 <- master_article_index_6_17 %>%
anti_join(anti_jack, by=c("file_id2"))
11449-11396
master_article_index_6_17 <- master_article_index_6_17 %>%
anti_join(anti_jack, by=c("file_id2"))
write.csv(master_article_index_6_17, "../data/master_article_index_6_17.csv")
years_6_17 <- extracted_article_index_6_17 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
years_6_17 <- master_article_index_6_17 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
main_index_10_30 <- read_csv("../data/mainindex_10_30.csv")
old_master_article_index_10.19 <- read.csv("../data/old_master_article_index_10.19.csv")
old_master_article_index_10.19 <- read.csv("../data/master_article_index_10.19.csv")
years_10_19 <- old_master_article_index_10.19 %>%
count(year) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
rename(pct_whole_old = pct_whole, count_old = count) %>%   mutate(rank_old = dense_rank(desc(pct_whole_old)))
year_compare <- years_10_19 %>%
inner_join(years_6_17, by="year") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
View(year_compare)
year_compare %>%
filter(count_old > count)
totals_6_17 <- master_article_index_6_17 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
View(totals_6_17)
View(old_master_article_index_10.19)
totals_6_17 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
totals_6_17 <- master_article_index_6_17 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
#Il (8%), AL, IA , IN (5%), AR (4.6%), AZ, VA, OH, WI, GA top newspaper states
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
compare <- totals_6_17 %>%
inner_join(totals_10_19, by="newspaper_state") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
View(totals_6_17)
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count_old = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count_old = n) %>%
mutate(pct_whole = round(count/sum(count)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count = n)
View(totals_10_19)
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(countold = n)
totals_10_19 <- old_master_article_index_10.19 %>%
count(newspaper_state) %>%
rename(count_old = n) %>%
mutate(pct_whole = round(count_old/sum(count_old)*100,2)) %>%
arrange(desc(pct_whole)) %>%
mutate(rank_new = dense_rank(desc(pct_whole)))
compare <- totals_6_17 %>%
inner_join(totals_10_19, by="newspaper_state") %>%
mutate(diff = (count-count_old)) %>%
mutate(pct_chg = round(count-count_old)/count_old*100) %>%
mutate(pct_chg = round(pct_chg,2))
View(compare)
compare %>%
filter(count_old > count)
#304 new pre-civil war articles extracted.
year_compare %>%
filter(year < "1862") %>%
summarize(sum(diff))
year_compare %>%
filter(year < "1862") %>%
count()
View(year_compare)
year_compare %>%
filter(year < "1862") %>%
summarize(sum(count))
