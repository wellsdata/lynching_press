---
title: "Text Compiler"
author: "Rob Wells"
date: "2024-6-18-23"
output: html_document
---
```{r}
library(tidyverse)
here::i_am("Text_Compiler_Article_Filter_6_17.rmd")

```


# Compiler of raw text. 
```{r include=FALSE}

#This was run once to compile the lynch object and  then used for tokenizing, etc

###
# List out text files that match pattern .txt, create DF
###
#loads 11490 articles
files <- list.files("~/Code/lynching_press/data/articles_may_16_2024/", pattern="*.txt") %>% 
  as.data.frame() %>%
  rename(filename = 1) 

index <- rio::import("../data/master_article_index_june_18_2024.csv") %>% 
  mutate(file_id = str_trim(file_id)) %>% 
  mutate(filename = paste0(file_id,".txt")) %>%
  inner_join(files) %>%
  mutate(filepath = paste0("~/Code/lynching_press/data/articles_may_16_2024/",filename))

#AI to the rescue
library(dplyr)
library(readr)
library(purrr)

# Function to process a chunk of rows
process_chunk <- function(chunk_rows, chunk_index) {
  articles_chunk <- tibble()
  
  for (row_value in chunk_rows) {
    temp <- index %>%
      slice(row_value)
    
    temp_filename <- temp$filename
    
    # Read lines from file
    tryCatch({
      articles_df_temp <- read_lines(temp$filepath) %>%
        as_tibble() %>%
        mutate(filename = temp_filename)
      
      # Append to chunk results
      articles_chunk <- bind_rows(articles_chunk, articles_df_temp)
    }, error = function(e) {
      message(paste("Error processing row", row_value, ":", conditionMessage(e)))
    })
  }
  
  # Write chunk to disk
  write_csv(articles_chunk, paste0("articles_chunk_", chunk_index, ".csv"))
}

# Determine chunk size and create chunks
chunk_size <- 500  # Adjust chunk size as needed
row_values <- split(1:nrow(index), ceiling(seq_along(1:nrow(index))/chunk_size))

# Process each chunk
walk2(row_values, seq_along(row_values), process_chunk)

# Combine all chunks into one data frame
chunk_files <- list.files(pattern = "articles_chunk_.*\\.csv")

articles_df <- map_dfr(chunk_files, read_csv)

# Perform the inner join after all files are processed
joined_df <- articles_df %>%
  select(filename, sentence = value) %>%
  inner_join(index, by = "filename")

write.csv(joined_df, ("../data/extracted_text_june_18_2024.csv"))

# View the resulting data frame
print(head(joined_df))

# 
# Processing in Chunks:
# 
# process_chunk function processes a specified chunk of rows and writes the result to a CSV file.
# chunk_size is set to 500, meaning it will process 500 rows at a time. Adjust this size based on your memory capacity.
# split(1:nrow(index), ceiling(seq_along(1:nrow(index))/chunk_size)) splits the rows into chunks.
# Writing Intermediate Results:
# 
# Each processed chunk is written to a CSV file using write_csv, with filenames like articles_chunk_1.csv, articles_chunk_2.csv, etc.
# Combining Results:
# 
# list.files(pattern = "articles_chunk_.*\\.csv") lists all chunk files.
# map_dfr(chunk_files, read_csv) reads and combines all the chunk files into one data frame articles_df.
# Inner Join:
# 
# After combining all the chunks, inner_join is performed on articles_df and index based on the filename column.
# This approach should help in managing memory usage efficiently and avoid running into memory exhaustion issues. Adjust the chunk size based on your specific system and dataset size.

```



```{r}
# Count the number of unique file names
#11396 articles
articles_df %>%
  summarize(n_unique_files = n_distinct(filename))


```


### Copy files from one directory to the other
```{r}

#This tutorial shows how to copy files from one directory to another
# https://stackoverflow.com/questions/68995687/r-move-files-to-folder-based-on-list-or-column

inputdir  <- "/Users/robwells/Code/hcij_lynching_phase_two/articles_10_19" 

#targetdir <- "/Users/robwells/Code/hcij_lynching_phase_two/narratives/code/articles_oct_19/" 

targetdir <- "/Users/robwells/Code/hcij_lynching_phase_two/narratives/data/articles_oct_19/" 

cleaned_articles_oct19 <- cleaned_articles_oct19 %>% 
   mutate(filename = paste(file_id2, ".txt", sep = ''))

#df <- extracted_articles_aug25$filename 

#creates new directory with 6448 articles: code/latest_articles/
filestocopy <- list.files(inputdir, full.names = TRUE) %>% 
  as_tibble() %>% 
  mutate(filename=(sub(".*/", "", value))) %>% 
  inner_join(cleaned_articles_oct19 , by=c("filename")) 
  #create a new column mutate = string-extract. keep everything after the last slash
  #inner_join to extracted articles aug 25
vector <- filestocopy$value
  #take that file path, select only filepath column and turn into a vector
  
filetocopy <- filestocopy[[1]]
#df_single <- df[[1]]
file.copy(from = filetocopy, to = targetdir)
map(vector, ~file.copy(from = inputdir, to=targetdir))

#map(filestocopy, ~file.copy(from = ., to=targetdir))


```

